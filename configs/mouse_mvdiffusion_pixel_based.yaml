# =============================================================================
# Mouse MVDiffusion Configuration - Pixel-Based (CoM + Pixel Scale)
# Multi-view diffusion for mouse 1-view to 6-view generation
# Using pixel-based preprocessing with CoM centering for Grade A quality
# =============================================================================

# Basic model configuration
n_views: 6
img_wh: 512
reference_view_idx: 0  # Which view to use as input (cam_000)
dataset_type: 'mouse'  # Use MouseMVDiffusionDataset

# Model paths
# Fine-tune from FaceLift pretrained (all components included!)
pretrained_model_name_or_path: 'checkpoints/mvdiffusion/pipeckpts'  # FaceLift pretrained (local)
pretrained_unet_path: null  # UNet already in pipeckpts
revision: null

# Prompt embeddings path (direction-based, can reuse from FaceLift)
prompt_embed_path: "mvdiffusion/data/fixed_prompt_embeds_6view/clr_embeds.pt"

# =============================================================================
# Dataset Configuration - Using Pixel-Based (CoM + Pixel Scale) Grade A
# =============================================================================
train_dataset:
  path: data_mouse_pixel_based/data_mouse_train.txt
  bg_color: 'three_choices'
  augmentation: true
  aug_brightness: [0.9, 1.1]
  aug_contrast: [0.9, 1.1]
  aug_hflip: false  # Disabled - would require camera pose adjustment

validation_dataset:
  path: data_mouse_pixel_based/data_mouse_val.txt
  bg_color: 'white'

# =============================================================================
# Output Directories
# =============================================================================
checkpoint_prefix: ''
output_dir: 'checkpoints/mvdiffusion/mouse_pixel_based'
val_out_dir: 'checkpoints/mvdiffusion/mouse_pixel_based/val/'

# =============================================================================
# Training Parameters
# =============================================================================
seed: 42
train_batch_size: 4  # Reduced due to limited data (original: 8)
validation_batch_size: 2
max_train_steps: 5000  # Shorter training for initial experiment
gradient_accumulation_steps: 4  # Effective batch = 16
gradient_checkpointing: true
learning_rate: 5e-5  # Lower LR for finetuning
step_rules: "1:100000,0.5"
scale_lr: false
lr_scheduler: "piecewise_constant"
lr_warmup_steps: 100
snr_gamma: 5.0
use_8bit_adam: false
allow_tf32: true
use_ema: true
dataloader_num_workers: 8

# Optimizer
adam_beta1: 0.9
adam_beta2: 0.999
adam_weight_decay: 1.e-2
adam_epsilon: 1.e-08
max_grad_norm: 1.0
prediction_type: null

# =============================================================================
# Logging and Validation - More frequent for monitoring
# =============================================================================
vis_dir: vis
logging_dir: logs
mixed_precision: 'fp16'
report_to: 'wandb'
local_rank: -1
checkpointing_steps: 500  # Save every 500 steps
checkpoints_total_limit: 5   # Keep 5 most recent
resume_from_checkpoint: null  # Start fresh from pretrained
enable_xformers_memory_efficient_attention: true
validation_steps: 100  # Validate every 100 steps (more frequent)
validation_sanity_check: true
tracker_project_name: 'mouse_facelift'  # Common project for all mouse experiments

# =============================================================================
# Training Specifics
# =============================================================================
trainable_modules: null  # Train all UNet modules
use_classifier_free_guidance: true
condition_drop_rate: 0.05
drop_type: 'drop_as_a_whole'
camera_embedding_lr_mult: 1.
scale_input_latents: true

# Pipeline parameters
pipe_kwargs:
  num_views: ${n_views}
validation_guidance_scales: [1., 3.]
validation_grid_nrow: ${n_views}
pipe_validation_kwargs:
  eta: 1.0

# =============================================================================
# UNet Configuration
# =============================================================================
unet_from_pretrained_kwargs:
  unclip: true
  num_views: ${n_views}
  sample_size: 64
  zero_init_conv_in: true
  init_mvattn_with_selfattn: false
  cd_attention_last: false
  cd_attention_mid: false
  multiview_attention: true
  sparse_mv_attention: true
  selfattn_block: custom
  addition_downsample: false

# =============================================================================
# Weights & Biases
# =============================================================================
wandb_exp_name: "mvdiff_pixel_based"
wandb_group: "mvdiffusion"  # Stage: mvdiffusion or gslrm
wandb_job_type: "finetune_com_centered"
