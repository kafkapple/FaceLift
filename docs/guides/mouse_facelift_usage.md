# Mouse-FaceLift Usage Guide

---
date: 2025-12-12
context_name: "2_Research"
tags: [ai-assisted, mouse-reconstruction, multi-view, 3d-reconstruction, mvdiffusion, gslrm]
project: FaceLift
status: active
generator: ai-assisted
generator_tool: claude-code
last_updated: 2025-12-12
---

## Overview

Mouse-FaceLift adapts the FaceLift 3D reconstruction pipeline for mouse multi-view data.
This guide covers environment setup, data preprocessing, training, and inference.

### í˜„ì¬ ìƒíƒœ (2025-12-12)

| ëª¨ë¸ | ìƒíƒœ | ì²´í¬í¬ì¸íŠ¸ |
|------|:----:|-----------|
| **GSLRM** | âœ… Fine-tuned | `checkpoints/gslrm/mouse_finetune/ckpt_*20000.pt` |
| **MVDiffusion** | ğŸ”„ í•™ìŠµì¤‘ | `checkpoints/mvdiffusion/mouse/` |

**Wandb**: Project `mouse_facelift`, Groups: `mvdiffusion`, `gslrm`

## Quick Start - ì „ì²´ íŒŒì´í”„ë¼ì¸ (gpu05)

### Step 0: í™˜ê²½ ì„¤ì •
```bash
ssh gpu05
cd /home/joon/FaceLift
conda activate mouse_facelift
```

### Step 1: ë°ì´í„° ì „ì²˜ë¦¬ (Video â†’ FaceLift Format)
```bash
# ì…ë ¥: /home/joon/data/markerless_mouse_1_nerf/
# ì¶œë ¥: data_mouse/
python scripts/process_mouse_data.py \
    --video_dir /home/joon/data/markerless_mouse_1_nerf/videos_undist \
    --meta_dir /home/joon/data/markerless_mouse_1_nerf \
    --output_dir data_mouse \
    --num_samples 2000

# ê²°ê³¼ í™•ì¸
ls data_mouse/
# data_mouse_train.txt, data_mouse_val.txt, sample_000000/, ...
```

### Step 2: Stage 1 - MVDiffusion Fine-tune (Single View â†’ 6 Views)
```bash
# Config: configs/mouse_mvdiffusion.yaml
# ì¶œë ¥: checkpoints/mvdiffusion/mouse/

# Single GPU
python train_diffusion.py --config configs/mouse_mvdiffusion.yaml

# Multi GPU (ê¶Œì¥)
accelerate launch --num_processes 4 \
    train_diffusion.py --config configs/mouse_mvdiffusion.yaml
```

### Step 3: Stage 2 - GSLRM Fine-tune (6 Views â†’ 3D Gaussian)
```bash
# Config: configs/mouse_config_finetune.yaml
# ì¶œë ¥: checkpoints/gslrm/mouse_finetune/

# Overfitting í…ŒìŠ¤íŠ¸ (ì„ íƒ)
python train_mouse.py --config configs/mouse_config_finetune.yaml --overfit 10

# Full training (Multi GPU)
torchrun --nproc_per_node 4 --nnodes 1 \
    --rdzv_id ${RANDOM} --rdzv_backend c10d --rdzv_endpoint localhost:29500 \
    train_mouse.py --config configs/mouse_config_finetune.yaml
```

### Step 4: ì¶”ë¡  - Single Image â†’ Multi-View ìƒì„±

```bash
# ì˜µì…˜ A: Zero123++ (pretrained, ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ìš©)
python inference_mouse.py \
    --input_image examples/mouse.png \
    --use_zero123pp \
    --checkpoint checkpoints/gslrm/mouse_finetune/ckpt_0000000000020000.pt \
    --output_dir outputs/

# ì˜µì…˜ B: MVDiffusion (fine-tuned, ê¶Œì¥) - MVDiffusion í•™ìŠµ ì™„ë£Œ í›„
python inference_mouse.py \
    --input_image examples/mouse.png \
    --mvdiffusion_checkpoint checkpoints/mvdiffusion/mouse/checkpoint-XXXXX \
    --checkpoint checkpoints/gslrm/mouse_finetune/ckpt_0000000000020000.pt \
    --output_dir outputs/

# ì˜µì…˜ C: 6-view ë°ì´í„° ì§ì ‘ ì…ë ¥ (ë„ë©”ì¸ ê°­ ì£¼ì˜)
python inference_mouse.py \
    --sample_dir data_mouse/sample_000000 \
    --checkpoint checkpoints/gslrm/mouse_finetune/ckpt_0000000000020000.pt \
    --output_dir outputs/
```

> **ë„ë©”ì¸ ê°­ ì£¼ì˜**: ì‹¤ì œ ì´ë¯¸ì§€ë¥¼ ì§ì ‘ GSLRMì— ì…ë ¥í•˜ë©´ í’ˆì§ˆì´ ì €í•˜ë  ìˆ˜ ìˆìŒ.
> End-to-End íŒŒì´í”„ë¼ì¸ (MVDiffusion â†’ GSLRM) ì‚¬ìš© ê¶Œì¥.
> ìì„¸í•œ ë‚´ìš©: [251212 ì—°êµ¬ë…¸íŠ¸](../reports/251212_research_mouse_facelift_daily.md)

### Step 5: ìµœì¢… ì¶œë ¥ë¬¼ í™•ì¸
```bash
ls outputs/{sample_name}/
# gaussians.ply        â† 3D Gaussian Splat (Blender/MeshLab)
# mesh.obj             â† 3D Mesh (Poisson reconstruction)
# turntable.mp4        â† 360Â° íšŒì „ ë¹„ë””ì˜¤
# render_grid.png      â† 6ê°œ ë·° ë Œë”ë§ ê·¸ë¦¬ë“œ
# generated_views/     â† ìƒì„±ëœ Multi-view ì´ë¯¸ì§€
```

### ì „ì²´ íŒŒì´í”„ë¼ì¸ ìš”ì•½

| Step | ì…ë ¥ | ì¶œë ¥ | ëª…ë ¹ì–´ |
|------|------|------|--------|
| 1. ì „ì²˜ë¦¬ | Video (6 views) | `data_mouse/` | `process_mouse_data.py` |
| 2. MVDiffusion | 1 view â†’ 6 views | `pipeckpts/` | `train_diffusion.py` |
| 3. GSLRM | 6 views â†’ 3D | `mouse_finetune/` | `train_mouse.py` |
| 4. ì¶”ë¡  | Single image | PLY/OBJ/MP4 | `inference_mouse.py` |

---

## GPU05 í™˜ê²½ ì„¤ì • (ì²˜ìŒ 1íšŒ)

### Step 1: Conda í™˜ê²½ ìƒì„± (ì´ë¯¸ ì™„ë£Œë¨)
```bash
# í™˜ê²½ì´ ì´ë¯¸ ìƒì„±ë˜ì–´ ìˆìŒ. í™•ì¸:
conda env list | grep mouse_facelift
# ì¶œë ¥: mouse_facelift    /home/joon/anaconda3/envs/mouse_facelift
```

### Step 2: í™˜ê²½ í™œì„±í™”
```bash
ssh gpu05
cd /home/joon/FaceLift
conda activate mouse_facelift   # CUDA/GCC í™˜ê²½ë³€ìˆ˜ ìë™ ì„¤ì •ë¨!
```

**ì°¸ê³ **: í™˜ê²½ë³€ìˆ˜ê°€ conda í™˜ê²½ì— ì˜êµ¬ ì„¤ì •ë˜ì–´ ìˆìŒ
- ìœ„ì¹˜: `~/anaconda3/envs/mouse_facelift/etc/conda/activate.d/env_vars.sh`
- `conda activate` ì‹œ CUDA 11.8, GCC-9 ìë™ ì„¤ì •
- `conda deactivate` ì‹œ ì›ë˜ í™˜ê²½ìœ¼ë¡œ ìë™ ë³µì›

### í™˜ê²½ í™œì„±í™” í™•ì¸
```bash
# í™•ì¸ ë°©ë²•:
echo $CUDA_HOME    # /usr/local/cuda-11.8
echo $CC           # /usr/bin/gcc-9
nvcc --version     # CUDA 11.8
python -c "import torch; print(torch.cuda.is_available())"  # True
```

---

## ë°ì´í„° ì „ì²˜ë¦¬ (í˜„ì¬ ë§ˆìš°ìŠ¤ ë°ì´í„° ê¸°ì¤€)

### í˜„ì¬ ë°ì´í„° ìœ„ì¹˜
```
/home/joon/data/markerless_mouse_1_nerf/
â”œâ”€â”€ videos_undist/          # 6ê°œ ë™ê¸°í™”ëœ ë¹„ë””ì˜¤
â”‚   â”œâ”€â”€ 0.mp4 (25.8MB)
â”‚   â”œâ”€â”€ 1.mp4 (17.6MB)
â”‚   â”œâ”€â”€ 2.mp4 (23.4MB)
â”‚   â”œâ”€â”€ 3.mp4 (21.6MB)
â”‚   â”œâ”€â”€ 4.mp4 (19.9MB)
â”‚   â””â”€â”€ 5.mp4 (25.0MB)
â”œâ”€â”€ simpleclick_undist/     # ë§ˆìŠ¤í¬ ë¹„ë””ì˜¤
â”‚   â”œâ”€â”€ 0.mp4 ~ 5.mp4
â”œâ”€â”€ new_cam.pkl             # ì¹´ë©”ë¼ ìº˜ë¦¬ë¸Œë ˆì´ì…˜
â””â”€â”€ keypoints2d_undist/     # 2D í‚¤í¬ì¸íŠ¸ (ì„ íƒ)
```

### ì „ì²˜ë¦¬ ì‹¤í–‰
```bash
# gpu05ì—ì„œ í™˜ê²½ í™œì„±í™” í›„:
source activate_gpu05.sh

# ë°ì´í„° ì „ì²˜ë¦¬ (ì•½ 2000ê°œ ìƒ˜í”Œ ì¶”ì¶œ)
python scripts/process_mouse_data.py \
    --video_dir /home/joon/data/markerless_mouse_1_nerf/videos_undist \
    --meta_dir /home/joon/data/markerless_mouse_1_nerf \
    --output_dir data_mouse \
    --num_samples 2000 \
    --image_size 512 \
    --num_views 6

# ì¶œë ¥ í™•ì¸
ls data_mouse/
# data_mouse_train.txt, data_mouse_val.txt, sample_000000/, ...
```

### ì¶œë ¥ êµ¬ì¡°
```
data_mouse/
â”œâ”€â”€ data_mouse_train.txt    # í•™ìŠµ ìƒ˜í”Œ ê²½ë¡œ ëª©ë¡
â”œâ”€â”€ data_mouse_val.txt      # ê²€ì¦ ìƒ˜í”Œ ê²½ë¡œ ëª©ë¡
â”œâ”€â”€ sample_000000/
â”‚   â”œâ”€â”€ images/
â”‚   â”‚   â”œâ”€â”€ cam_000.png     # 512x512 RGBA
â”‚   â”‚   â”œâ”€â”€ cam_001.png
â”‚   â”‚   â”œâ”€â”€ cam_002.png
â”‚   â”‚   â”œâ”€â”€ cam_003.png
â”‚   â”‚   â”œâ”€â”€ cam_004.png
â”‚   â”‚   â””â”€â”€ cam_005.png
â”‚   â””â”€â”€ opencv_cameras.json # ì¹´ë©”ë¼ íŒŒë¼ë¯¸í„°
â”œâ”€â”€ sample_000001/
â”‚   â””â”€â”€ ...
â””â”€â”€ ...
```

---

## íŒŒì´í”„ë¼ì¸ ê°œìš”

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Mouse-FaceLift ì „ì²´ íŒŒì´í”„ë¼ì¸                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                             â”‚
â”‚  Single Image â”€â”€â”¬â”€â”€â–º MVDiffusion (fine-tuned) â”€â”€â–º 6 Views â”€â”€â–º GSLRM â”€â”€â–º PLY â”‚
â”‚                 â”‚                                  â†‘                        â”‚
â”‚                 â””â”€â”€â–º Zero123++ (pretrained) â”€â”€â”€â”€â”€â”€â”€â”˜                        â”‚
â”‚                                                                             â”‚
â”‚  ë‘ ëª¨ë¸ì€ ë³„ë„ í•™ìŠµ ê°€ëŠ¥ (Stage 1: MVDiffusion, Stage 2: GSLRM)               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## í•™ìŠµ

### Stage 1: MVDiffusion Fine-tune (Single View â†’ 6 Views)

```bash
# MVDiffusion í•™ìŠµ (single GPU)
python train_diffusion.py --config configs/mouse_mvdiffusion.yaml

# MVDiffusion í•™ìŠµ (multi GPU)
accelerate launch --num_processes 4 \
    train_diffusion.py --config configs/mouse_mvdiffusion.yaml
```

**Config**: `configs/mouse_mvdiffusion.yaml`
- `max_train_steps`: 30,000
- `learning_rate`: 5e-5
- `train_batch_size`: 4
- `gradient_accumulation_steps`: 4 (effective batch = 16)

### Stage 2: GSLRM Fine-tune (6 Views â†’ 3D Gaussian)

#### Step 1: Overfitting í…ŒìŠ¤íŠ¸ (í•„ìˆ˜ ê¶Œì¥)
```bash
# 10ê°œ ìƒ˜í”Œë¡œ ì½”ë“œ ì •ìƒ ë™ì‘ í™•ì¸
python train_mouse.py --config configs/mouse_config.yaml --overfit 10
```

**ê¸°ëŒ€ ê²°ê³¼**:
- Lossê°€ 0ì— ê°€ê¹ê²Œ ê°ì†Œ
- ì…ë ¥ ì´ë¯¸ì§€ê°€ ì™„ë²½í•˜ê²Œ ë³µì›ë¨
- ì´ê²ƒì´ ì„±ê³µí•´ì•¼ ì „ì²´ í•™ìŠµ ì§„í–‰

#### Step 2: ì „ì²´ í•™ìŠµ

```bash
# ë‹¨ì¼ GPU
python train_mouse.py --config configs/mouse_config.yaml

# ë©€í‹° GPU (ê¶Œì¥)
torchrun --nproc_per_node 4 --nnodes 1 \
    --rdzv_id ${RANDOM} --rdzv_backend c10d --rdzv_endpoint localhost:29500 \
    train_mouse.py --config configs/mouse_config.yaml
```

#### Step 3: ì²´í¬í¬ì¸íŠ¸ì—ì„œ ì¬ê°œ
```bash
python train_mouse.py --config configs/mouse_config.yaml \
    --load checkpoints/gslrm/mouse/
```

---

## ì¶”ë¡ 

### ì˜µì…˜ 1: Zero123++ (pretrained) + GSLRM

```bash
# Single image â†’ Zero123++ â†’ GSLRM â†’ PLY/OBJ/Video
python inference_mouse.py \
    --input_image path/to/mouse.png \
    --use_zero123pp \
    --checkpoint checkpoints/gslrm/mouse/ \
    --output_dir outputs/
```

**íŠ¹ì§•**:
- Zero123++ëŠ” pretrained ëª¨ë¸ ì‚¬ìš© (HuggingFaceì—ì„œ ìë™ ë‹¤ìš´ë¡œë“œ)
- ë¹ ë¥´ê²Œ í…ŒìŠ¤íŠ¸ ê°€ëŠ¥

### ì˜µì…˜ 2: MVDiffusion (fine-tuned) + GSLRM

```bash
# Single image â†’ MVDiffusion â†’ GSLRM â†’ PLY/OBJ/Video
python inference_mouse.py \
    --input_image path/to/mouse.png \
    --mvdiffusion_checkpoint checkpoints/experiments/train/mouse_mvdiffusion/pipeckpts \
    --checkpoint checkpoints/gslrm/mouse/ \
    --output_dir outputs/
```

**íŠ¹ì§•**:
- Mouse ë°ì´í„°ë¡œ fine-tuned MVDiffusion ì‚¬ìš©
- ë” ì •í™•í•œ multi-view ìƒì„± ê¸°ëŒ€

### ì˜µì…˜ 3: 6-view ìƒ˜í”Œì—ì„œ ì§ì ‘ ì¶”ë¡ 

```bash
# ì´ë¯¸ 6ê°œ ë·°ê°€ ìˆëŠ” ê²½ìš°
python inference_mouse.py \
    --sample_dir data_mouse/sample_000000 \
    --checkpoint checkpoints/gslrm/mouse/ \
    --output_dir outputs/
```

### ì¶”ë¡  íŒŒë¼ë¯¸í„°

| íŒŒë¼ë¯¸í„° | Zero123++ | MVDiffusion | ì„¤ëª… |
|---------|-----------|-------------|------|
| `--*_steps` | 75 | 50 | Diffusion steps |
| `--*_guidance` | 4.0 | 3.0 | CFG guidance scale |
| `--seed` | 42 | 42 | Random seed |

### ì¶œë ¥ íŒŒì¼

```
outputs/{sample_name}/
â”œâ”€â”€ gaussians.ply           # 3D Gaussian splat (Blender/MeshLab í˜¸í™˜)
â”œâ”€â”€ mesh.obj                # Mesh (Poisson reconstruction)
â”œâ”€â”€ turntable.mp4           # 360Â° íšŒì „ ë¹„ë””ì˜¤
â”œâ”€â”€ render_view_*.png       # ê° ë·° ë Œë”ë§
â”œâ”€â”€ render_grid.png         # 6ê°œ ë·° ê·¸ë¦¬ë“œ
â””â”€â”€ generated_views/        # MVDiffusion/Zero123++ ìƒì„± ì´ë¯¸ì§€
    â”œâ”€â”€ view_00.png ~ view_05.png
```

---

## ì„¤ì • íŒŒì¼ (Config)

### Config íŒŒì¼ ë¹„êµí‘œ

| Config íŒŒì¼ | ìš©ë„ | max_steps | warmup | LR | batch_size |
|-------------|------|-----------|--------|-----|------------|
| `mouse_config.yaml` | ê¸°ë³¸ í•™ìŠµ (scratch) | **100,000** | 200 | 5e-5 | 2 |
| `mouse_config_finetune.yaml` | FaceLift pretrained fine-tune | **20,000** | 100 | 2e-5 | 2 |
| `mouse_config_debug.yaml` | ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ (~10-30ë¶„) | **1,000** | 50 | 1e-4 | 4 |

### ê³µí†µ ëª¨ë¸ ì„¤ì •

```yaml
model:
  image_tokenizer:
    image_size: 512            # ì…ë ¥ ì´ë¯¸ì§€ í¬ê¸°
    patch_size: 8              # ViT íŒ¨ì¹˜ í¬ê¸°
    in_channels: 9             # 3 RGB + 3 direction + 3 Reference

  transformer:
    d: 1024                    # íˆë“  ì°¨ì›
    d_head: 64                 # ì–´í…ì…˜ í—¤ë“œ ì°¨ì›
    n_layer: 24                # íŠ¸ëœìŠ¤í¬ë¨¸ ë ˆì´ì–´ ìˆ˜

  gaussians:
    n_gaussians: 2             # 12288 (ì‹¤ì œ)
    sh_degree: 0
```

### ë°ì´í„° ì„¤ì •

```yaml
training:
  dataset:
    dataset_path: "data_mouse/data_mouse_train.txt"
    num_views: 6               # ì´ 6ê°œ ë·°
    num_input_views: 1         # ì…ë ¥: ë‹¨ì¼ ë·°
    target_has_input: true     # íƒ€ê²Ÿì— ì…ë ¥ í¬í•¨
    background_color: "white"
```

### Loss ê°€ì¤‘ì¹˜

```yaml
losses:
  l2_loss_weight: 1.0          # MSE ì†ì‹¤
  lpips_loss_weight: 0.5       # LPIPS ì§€ê° ì†ì‹¤
  perceptual_loss_weight: 0.5  # VGG ì§€ê° ì†ì‹¤
  ssim_loss_weight: 0.2        # êµ¬ì¡°ì  ìœ ì‚¬ë„ ì†ì‹¤
  pixelalign_loss_weight: 0.0  # ë¹„í™œì„±í™”
  pointsdist_loss_weight: 0.0  # ë¹„í™œì„±í™”
```

### ì²´í¬í¬ì¸íŠ¸ ì„¤ì •

| Config | resume_ckpt | checkpoint_dir |
|--------|-------------|----------------|
| ê¸°ë³¸ | `checkpoints/gslrm` | `checkpoints/gslrm/mouse` |
| fine-tune | `ckpt_0000000000021125.pt` (FaceLift pretrained) | `checkpoints/gslrm/mouse_finetune` |
| debug | `checkpoints/gslrm/stage_2` | `checkpoints/gslrm/mouse_debug` |

### Validation ì„¤ì •

```yaml
validation:
  enabled: true                # ê¸°ë³¸/fine-tune: true, debug: false
  val_every: 500               # 500 steps ë§ˆë‹¤ ê²€ì¦
  dataset_path: "data_mouse/data_mouse_val.txt"
```

### Inference ì„¤ì •

```yaml
inference:
  enabled: false               # í˜„ì¬ ëª¨ë“  configì—ì„œ ë¹„í™œì„±í™”
  output_dir: "experiments/inference/mouse"
```

### Mouse íŠ¹í™” ì„¤ì •

```yaml
mouse:
  camera:
    num_views: 6
    camera_distance: 2.7

  augmentation:
    enabled: true              # debugì—ì„œëŠ” false
    horizontal_flip: true
    brightness_range: [0.9, 1.1]
    contrast_range: [0.9, 1.1]
```

### ê¶Œì¥ ì‚¬ìš© ì‹œë‚˜ë¦¬ì˜¤

| ì‹œë‚˜ë¦¬ì˜¤ | Config íŒŒì¼ | ì„¤ëª… |
|----------|-------------|------|
| ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ | `mouse_config_debug.yaml` | 1000 steps, ~10-30ë¶„, wandb offline |
| Fine-tune | `mouse_config_finetune.yaml` | FaceLift pretrained â†’ 20k steps |
| Full í•™ìŠµ | `mouse_config.yaml` | scratch â†’ 100k steps |

```bash
# ì˜ˆì‹œ: Fine-tune ì‹¤í–‰
python train_mouse.py --config configs/mouse_config_finetune.yaml

# ì˜ˆì‹œ: Debug ëª¨ë“œ ì‹¤í–‰
python train_mouse.py --config configs/mouse_config_debug.yaml
```

---

## ë¬¸ì œ í•´ê²°

### CLIPTokenizer merges.txt ì˜¤ë¥˜
```
TypeError: expected str, bytes or os.PathLike object, not NoneType
```

**ì›ì¸**: CLIPTokenizerì— í•„ìš”í•œ `merges.txt` íŒŒì¼ ëˆ„ë½

**í•´ê²°**: ìë™ ë‹¤ìš´ë¡œë“œ ë¡œì§ì´ í¬í•¨ë˜ì–´ ìˆìŒ (v2024.12.10+). ìˆ˜ë™ í•´ê²° í•„ìš” ì‹œ:
```bash
cd checkpoints/mvdiffusion/pipeckpts/tokenizer
wget https://huggingface.co/openai/clip-vit-large-patch14/resolve/main/merges.txt
```

ìì„¸í•œ ë‚´ìš©: [docs/troubleshooting/clip_tokenizer_merges_error.md](../troubleshooting/clip_tokenizer_merges_error.md)

### CUDA Out of Memory
```yaml
# batch_size ì¤„ì´ê¸°
training:
  dataloader:
    batch_size_per_gpu: 1
```

### CUDA ë²„ì „ ë¶ˆì¼ì¹˜ ì—ëŸ¬
```bash
# ë°˜ë“œì‹œ activate_gpu05.shë¡œ í™˜ê²½ í™œì„±í™”
source activate_gpu05.sh

# í™•ì¸
echo $CUDA_HOME  # /usr/local/cuda-11.8 ì´ì–´ì•¼ í•¨
```

### í•™ìŠµì´ ìˆ˜ë ´í•˜ì§€ ì•ŠìŒ
1. Overfitting í…ŒìŠ¤íŠ¸ ë¨¼ì € ì‹¤í–‰
2. `checkpoints/*/data_examples/` ì—ì„œ ë°ì´í„° ì‹œê°í™” í™•ì¸
3. ì¹´ë©”ë¼ íŒŒë¼ë¯¸í„° ê²€ì¦
4. í•™ìŠµë¥  ë‚®ì¶”ê¸°

---

## Git ë™ê¸°í™” ì›Œí¬í”Œë¡œìš°

### ë¡œì»¬ì—ì„œ ì½”ë“œ ìˆ˜ì • í›„
```bash
cd /home/joon/dev/FaceLift
git add -A
git commit -m "feat(mouse): description"
git push
```

### gpu05ì—ì„œ í•™ìŠµ ì „
```bash
ssh gpu05
cd /home/joon/FaceLift
git pull
source activate_gpu05.sh
```

### gpu05ì—ì„œ í•™ìŠµ í›„
```bash
# ì²´í¬í¬ì¸íŠ¸ ì»¤ë°‹ (ì„ íƒ)
git add checkpoints/ outputs/
git commit -m "chore: add training checkpoints"
git push

# ë¡œì»¬ì—ì„œ pull
cd /home/joon/dev/FaceLift
git pull
```

---

## íŒŒì¼ ì°¸ì¡°

### GSLRM (Stage 2: 6 Views â†’ 3D)

| íŒŒì¼ | ìš©ë„ |
|------|------|
| `train_mouse.py` | GSLRM í•™ìŠµ ìŠ¤í¬ë¦½íŠ¸ |
| `inference_mouse.py` | í†µí•© ì¶”ë¡  ìŠ¤í¬ë¦½íŠ¸ (Zero123++/MVDiffusion + GSLRM) |
| `gslrm/data/mouse_dataset.py` | GSLRMìš© PyTorch Dataset |
| `configs/mouse_config.yaml` | GSLRM ê¸°ë³¸ í•™ìŠµ (100k steps) |
| `configs/mouse_config_finetune.yaml` | GSLRM Fine-tune (20k steps) |
| `configs/mouse_config_debug.yaml` | GSLRM ë””ë²„ê·¸ (1k steps) |

### MVDiffusion (Stage 1: Single View â†’ 6 Views)

| íŒŒì¼ | ìš©ë„ |
|------|------|
| `train_diffusion.py` | MVDiffusion í•™ìŠµ ìŠ¤í¬ë¦½íŠ¸ |
| `configs/mouse_mvdiffusion.yaml` | MVDiffusion fine-tune ì„¤ì • (30k steps) |
| `mvdiffusion/data/mouse_dataset.py` | MVDiffusionìš© PyTorch Dataset |
| `mvdiffusion/pipelines/pipeline_mvdiffusion_unclip.py` | MVDiffusion ì¶”ë¡  íŒŒì´í”„ë¼ì¸ |
| `mvdiffusion/pipelines/zero123pp_pipeline.py` | Zero123++ ì¶”ë¡  íŒŒì´í”„ë¼ì¸ |

### í™˜ê²½ ë° ìœ í‹¸ë¦¬í‹°

| íŒŒì¼ | ìš©ë„ |
|------|------|
| `setup_mouse_env.sh` | Conda í™˜ê²½ ì„¤ì • (1íšŒ) |
| `scripts/process_mouse_data.py` | ë¹„ë””ì˜¤ â†’ FaceLift í¬ë§· ë³€í™˜ |
| `scripts/download_weights.py` | Pretrained ê°€ì¤‘ì¹˜ ë‹¤ìš´ë¡œë“œ |

---

## ì²´í¬ë¦¬ìŠ¤íŠ¸

- [ ] `source activate_gpu05.sh` ì‹¤í–‰ í™•ì¸
- [ ] ë°ì´í„° ì „ì²˜ë¦¬ ì™„ë£Œ (`data_mouse/` ìƒì„±)
- [ ] Overfitting í…ŒìŠ¤íŠ¸ í†µê³¼
- [ ] ì „ì²´ í•™ìŠµ ì‹¤í–‰
- [ ] ê²°ê³¼ í‰ê°€
