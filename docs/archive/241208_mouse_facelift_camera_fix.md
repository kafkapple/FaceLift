# Mouse-FaceLift ì¹´ë©”ë¼ íŒŒë¼ë¯¸í„° ë²„ê·¸ ìˆ˜ì • ë° íŒŒì´í”„ë¼ì¸ ê°€ì´ë“œ

- **ë‚ ì§œ**: 2024-12-08
- **ì£¼ì œ**: ì¹´ë©”ë¼ íŒŒë¼ë¯¸í„° ë²„ê·¸ ë¶„ì„ ë° ìˆ˜ì •
- **ëª©ì **: í•™ìŠµ/ì¶”ë¡  ì‹¤íŒ¨ ì›ì¸ ë¶„ì„ ë° í•´ê²°

---

## 1. ë°œê²¬ëœ ë¬¸ì œì 

### 1.1 ì¹´ë©”ë¼ ë°ì´í„° ë¡œë”© ë²„ê·¸

**ìœ„ì¹˜**: `scripts/process_mouse_data.py` - `load_camera_params()` í•¨ìˆ˜

**ë¬¸ì œ**: MAMMAL ì¹´ë©”ë¼ ë°ì´í„°ëŠ” **LIST** í˜•ì‹ì¸ë°, ì½”ë“œê°€ **DICT**ë¡œ ì²˜ë¦¬

```python
# ë²„ê·¸ ì½”ë“œ
cam_dict = pickle.load(f)
for i in range(num_views):
    if i in cam_dict:  # LISTì—ì„œ 'in' ì—°ì‚°ì€ ê°’ ê²€ì‚¬, ì¸ë±ìŠ¤ ê²€ì‚¬ ì•„ë‹˜!
        cameras.append(cam_dict[i])
```

**ê²°ê³¼**: ì‹¤ì œ ì¹´ë©”ë¼ ëŒ€ì‹  ê¸°ë³¸ flat ì¹´ë©”ë¼ë¡œ ëŒ€ì²´ë¨

### 1.2 ì¹´ë©”ë¼ ê±°ë¦¬ ë¶ˆì¼ì¹˜

| íŒŒë¼ë¯¸í„° | MAMMAL ì‹¤ì œ | FaceLift ê¸°ëŒ€ê°’ | ê¸°ì¡´ ì½”ë“œ (ë²„ê·¸) |
|---------|-------------|----------------|-----------------|
| ê±°ë¦¬ | 246-414 ë‹¨ìœ„ | ~2.7 ë‹¨ìœ„ | 2.7 (ê¸°ë³¸ê°’) |
| ê³ ë„ê° | 11-31Â° (ë‹¤ì–‘) | 20Â° | 0Â° (flat) |
| ë°©ìœ„ê° | ë¶ˆê·œì¹™ ë°°ì¹˜ | turntable | ê· ë“± 60Â° ê°„ê²© |
| FOV | 40-44Â° | 50Â° | 50Â° |

### 1.3 MAMMAL ì‹¤ì œ ì¹´ë©”ë¼ ì •ë³´

```
Camera 0: dist=246.1, elevation=14.9Â°, azimuth=-147.0Â°, FOV=40.4Â°
Camera 1: dist=414.5, elevation=20.6Â°, azimuth=34.0Â°, FOV=43.6Â°
Camera 2: dist=363.7, elevation=11.3Â°, azimuth=86.1Â°, FOV=41.1Â°
Camera 3: dist=340.0, elevation=10.7Â°, azimuth=-11.3Â°, FOV=39.9Â°
Camera 4: dist=318.3, elevation=26.5Â°, azimuth=144.0Â°, FOV=43.2Â°
Camera 5: dist=305.7, elevation=30.8Â°, azimuth=-64.1Â°, FOV=41.1Â°
```

---

## 2. ì ìš©ëœ ìˆ˜ì •ì‚¬í•­

### 2.1 `load_camera_params()` ìˆ˜ì •

```python
# ìˆ˜ì •ëœ ì½”ë“œ
cam_data = pickle.load(f)

# Handle both list and dict formats
if isinstance(cam_data, list):
    # MAMMAL format: list of camera dicts
    for i in range(min(num_views, len(cam_data))):
        cameras.append(cam_data[i])
elif isinstance(cam_data, dict):
    # Dict format with integer or string keys
    for i in range(num_views):
        if i in cam_data:
            cameras.append(cam_data[i])
        elif str(i) in cam_data:
            cameras.append(cam_data[str(i)])
```

### 2.2 `convert_to_facelift_format()` ìˆ˜ì •

- ì¹´ë©”ë¼ ê±°ë¦¬ ì •ê·œí™” ì¶”ê°€ (í‰ê·  ê±°ë¦¬ â†’ 2.7)
- FaceLift í‘œì¤€ intrinsics ì‚¬ìš© (FOV 50Â°)
- CLI ì˜µì…˜ ì¶”ê°€: `--target_distance`, `--target_fov`

### 2.3 `generate_default_cameras()` ìˆ˜ì •

- elevation íŒŒë¼ë¯¸í„° ì¶”ê°€ (ê¸°ë³¸ê°’: 20Â°)
- FaceLift `get_turntable_cameras()`ì™€ ë™ì¼í•œ ì¹´ë©”ë¼ ë°°ì¹˜

**ì»¤ë°‹**: `c14d9c1` - `fix(mouse): fix camera loading and add distance normalization`

---

## 3. íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ê°€ì´ë“œ

### 3.0 ì‚¬ì „ ì¤€ë¹„ (gpu05)

```bash
# gpu05 ì ‘ì†
ssh gpu05

# kafka ë“œë¼ì´ë¸Œ ë§ˆìš´íŠ¸ í™•ì¸
ls /media/joon/kafka/data/raw/markerless_mouse_1_nerf/
# ì—†ìœ¼ë©´: sudo mount /dev/sdb1 /media/joon/kafka

# conda í™˜ê²½ í™œì„±í™”
source ~/anaconda3/etc/profile.d/conda.sh
conda activate mouse_facelift

# ì½”ë“œ ìµœì‹ í™”
cd /home/joon/FaceLift
git pull origin main
```

### 3.1 ë°ì´í„° ì „ì²˜ë¦¬

```bash
# ê¸°ì¡´ ë°ì´í„° ë°±ì—…
mv data_mouse data_mouse_old_$(date +%Y%m%d)

# ë°ì´í„° ì¬ì „ì²˜ë¦¬ (ì¹´ë©”ë¼ ì •ê·œí™” í¬í•¨)
python scripts/process_mouse_data.py \
    --video_dir /media/joon/kafka/data/raw/markerless_mouse_1_nerf/videos_undist \
    --meta_dir /media/joon/kafka/data/raw/markerless_mouse_1_nerf \
    --output_dir data_mouse \
    --num_samples 2000 \
    --num_views 6 \
    --image_size 512 \
    --target_distance 2.7 \
    --target_fov 50 \
    --val_ratio 0.1
```

**í™•ì¸ ì‚¬í•­**:
```
Camera normalization: avg_dist=XXX.X, target=2.7, scale=0.XXXXXX
Camera 0 after norm: dist=2.70, elev=XX.XÂ°, fx=549.0, fov=50.0Â°
```

### 3.2 Pretrained ì²´í¬í¬ì¸íŠ¸ ë‹¤ìš´ë¡œë“œ

```bash
# HuggingFace í† í° ì„¤ì •
echo "HF_TOKEN=your_huggingface_token" > .env

# ì²´í¬í¬ì¸íŠ¸ ë‹¤ìš´ë¡œë“œ
python scripts/download_checkpoints.py

# í™•ì¸
ls -la checkpoints/gslrm/
```

### 3.3 í•™ìŠµ ì‹¤í–‰

```bash
# ë””ë²„ê·¸ ëª¨ë“œ (ë¹ ë¥¸ í…ŒìŠ¤íŠ¸, ~30ë¶„)
python train_mouse.py --config configs/mouse_config_debug.yaml

# ì „ì²´ í•™ìŠµ (Single GPU)
python train_mouse.py --config configs/mouse_config.yaml

# Multi-GPU í•™ìŠµ (ê¶Œì¥)
torchrun --nproc_per_node=4 train_mouse.py --config configs/mouse_config.yaml
```

### 3.4 ì¶”ë¡ 

```bash
# ë‹¨ì¼ ì´ë¯¸ì§€ ì¶”ë¡ 
python inference_mouse.py \
    --input_image path/to/mouse.png \
    --output_dir outputs/test/ \
    --checkpoint checkpoints/gslrm/mouse/

# ë””ë ‰í† ë¦¬ ì¶”ë¡ 
python inference_mouse.py \
    --input_dir data_mouse/sample_000000/images/ \
    --output_dir outputs/sample_000000/ \
    --checkpoint checkpoints/gslrm/mouse/
```

---

## 4. ë°ì´í„° êµ¬ì¡°

### 4.1 ì›ë³¸ ë°ì´í„° (MAMMAL)

```
/media/joon/kafka/data/raw/markerless_mouse_1_nerf/
â”œâ”€â”€ new_cam.pkl              # ì¹´ë©”ë¼ íŒŒë¼ë¯¸í„° (LIST of 6 cameras)
â”œâ”€â”€ videos_undist/           # 6ê°œ ë·° ë¹„ë””ì˜¤ (0.mp4 ~ 5.mp4)
â””â”€â”€ simpleclick_undist/      # Segmentation ë§ˆìŠ¤í¬ ë¹„ë””ì˜¤
```

### 4.2 ì „ì²˜ë¦¬ëœ ë°ì´í„°

```
data_mouse/
â”œâ”€â”€ data_mouse_train.txt     # í•™ìŠµ ìƒ˜í”Œ ê²½ë¡œ (1,799ê°œ)
â”œâ”€â”€ data_mouse_val.txt       # ê²€ì¦ ìƒ˜í”Œ ê²½ë¡œ (199ê°œ)
â””â”€â”€ sample_XXXXXX/
    â”œâ”€â”€ opencv_cameras.json  # FaceLift í˜•ì‹ ì¹´ë©”ë¼
    â””â”€â”€ images/
        â”œâ”€â”€ cam_000.png      # RGBA (512x512, ë§ˆìŠ¤í¬ í¬í•¨)
        â”œâ”€â”€ cam_001.png
        â””â”€â”€ ...
```

### 4.3 opencv_cameras.json í˜•ì‹

```json
{
  "frames": [
    {
      "w": 512, "h": 512,
      "fx": 549.0, "fy": 549.0,
      "cx": 256.0, "cy": 256.0,
      "w2c": [[...], [...], [...], [...]],  // 4x4 world-to-camera
      "file_path": "images/cam_000.png",
      "view_id": 0
    },
    ...
  ]
}
```

---

## 5. Novel View Synthesis

### 5.1 ê¸°ë³¸ ê°œë…

FaceLiftëŠ” **3D Gaussian Splatting** ê¸°ë°˜ìœ¼ë¡œ, ì…ë ¥ ì´ë¯¸ì§€ë¡œë¶€í„° 3D í‘œí˜„ì„ ìƒì„±í•˜ê³  **ì„ì˜ì˜ ì¹´ë©”ë¼ ìœ„ì¹˜**ì—ì„œ ë Œë”ë§ ê°€ëŠ¥.

- í•™ìŠµ ë°ì´í„°: 6ê°œ ë·°
- ì¶œë ¥ ê°€ëŠ¥ ë·°: **ë¬´ì œí•œ** (ì„ì˜ì˜ ì¹´ë©”ë¼ ìœ„ì¹˜)

### 5.2 ë‹¤ì–‘í•œ ë·° ìƒì„± ë°©ë²•

```python
from gslrm.model.gaussians_renderer import get_turntable_cameras

# 24ê°œ ë·° turntable
w, h, num_views, fxfycxcy, c2ws = get_turntable_cameras(
    hfov=50,
    num_views=24,
    w=512, h=512,
    radius=2.7,
    elevation=20
)

# ë‹¤ì–‘í•œ ê³ ë„ì—ì„œ ì´¬ì˜
for elev in [0, 15, 30, 45]:
    cameras = get_turntable_cameras(num_views=8, elevation=elev)
```

### 5.3 360Â° íšŒì „ ë¹„ë””ì˜¤ ìƒì„±

```python
# 60 í”„ë ˆì„ íšŒì „ ë¹„ë””ì˜¤
cameras = get_turntable_cameras(num_views=60, elevation=20)
# ë Œë”ë§ í›„ videoioë¡œ ì €ì¥
```

---

## 6. ì£¼ìš” ì„¤ì • íŒŒì¼

### 6.1 configs/mouse_config.yaml

| ì„¹ì…˜ | íŒŒë¼ë¯¸í„° | ê°’ | ì„¤ëª… |
|-----|---------|-----|------|
| model.gaussians | n_gaussians | 2 | Gaussian ìˆ˜ (12288ë¡œ ì¦ê°€ ê°€ëŠ¥) |
| training.dataset | num_views | 6 | ë·° ìˆ˜ |
| training.dataset | num_input_views | 1 | ì…ë ¥ ë·° ìˆ˜ |
| training.optimizer | lr | 0.00005 | í•™ìŠµë¥  |
| training.schedule | max_fwdbwd_passes | 100000 | ìµœëŒ€ ìŠ¤í… |
| training.checkpointing | resume_ckpt | checkpoints/gslrm | Pretrained ì²´í¬í¬ì¸íŠ¸ |

### 6.2 configs/mouse_config_debug.yaml

ë””ë²„ê·¸ìš© ë¹ ë¥¸ ì„¤ì •:
- `max_fwdbwd_passes: 1000`
- `batch_size_per_gpu: 4`
- `wandb.offline: true`

---

## 7. ë¬¸ì œ í•´ê²°

### Q: í•™ìŠµì´ ë„ˆë¬´ ë¹¨ë¦¬ ëë‚¨
**A**: `max_fwdbwd_passes` ê°’ í™•ì¸ (10000 â†’ 100000)

### Q: ì¶”ë¡  ê²°ê³¼ê°€ ì´ìƒí•¨
**A**:
1. ì¹´ë©”ë¼ íŒŒë¼ë¯¸í„° í™•ì¸ (`opencv_cameras.json`)
2. Pretrained ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ í™•ì¸
3. ë°ì´í„° ì¬ì „ì²˜ë¦¬ í•„ìš”

### Q: kafka ë§ˆìš´íŠ¸ ì•ˆë¨
**A**: `sudo mount /dev/sdb1 /media/joon/kafka`

---

## 8. ì°¸ê³  ìë£Œ

- FaceLift ë…¼ë¬¸: [arXiv link]
- GS-LRM: Gaussian Splatting Large Reconstruction Model
- MAMMAL ë°ì´í„°ì…‹: Multi-view Animal Motion capture

---

*ğŸ¤– Generated with Claude Code*
